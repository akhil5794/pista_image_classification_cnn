{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. ResNet50\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a custom classification head on top of the pre-trained model\n",
    "flatten = Flatten()(resnet_model.output)\n",
    "dense1 = Dense(256, activation='relu')(flatten)\n",
    "output = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=resnet_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "epochs = 20  # Adjust the number of epochs as needed\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs, validation_data=test_generator\n",
    ")\n",
    "\n",
    "# Generate predictions for the train data\n",
    "train_pred = model.predict(train_generator)\n",
    "train_pred_labels = np.argmax(train_pred, axis=1)  # Assuming the predicted probabilities are in one-hot encoded format\n",
    "\n",
    "# Collect the true class labels for the train data\n",
    "train_true_labels = train_generator.classes\n",
    "\n",
    "# Compute the confusion matrix for the train data\n",
    "train_cm = classification_report(train_true_labels, train_pred_labels)\n",
    "\n",
    "# Generate predictions for the test data\n",
    "test_pred = model.predict(test_generator)\n",
    "test_pred_labels = np.argmax(test_pred, axis=1)  # Assuming the predicted probabilities are in one-hot encoded format\n",
    "\n",
    "# Collect the true class labels for the test data\n",
    "test_true_labels = test_generator.classes\n",
    "\n",
    "# Compute the confusion matrix for the test data\n",
    "test_cm = classification_report(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(\"Confusion Matrix (Train Data):\")\n",
    "print(train_cm)\n",
    "\n",
    "print(\"Confusion Matrix (Test Data):\")\n",
    "print(test_cm)\n",
    "\n",
    "# Get the training loss and accuracy values from the history object\n",
    "train_loss = history.history['loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "\n",
    "# Get the validation loss and accuracy values from the history object\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig()\n",
    "\n",
    "## 4. MobileNet\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model\n",
    "mobilenet_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in mobilenet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a custom classification head on top of the pre-trained model\n",
    "global_avg_pooling = GlobalAveragePooling2D()(mobilenet_model.output)\n",
    "dense1 = Dense(256, activation='relu')(global_avg_pooling)\n",
    "output = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=mobilenet_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "epochs = 20  # Adjust the number of epochs as needed\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs, validation_data=test_generator\n",
    ")\n",
    "\n",
    "# Generate predictions for the train data\n",
    "train_pred = model.predict(train_generator)\n",
    "train_pred_labels = np.argmax(train_pred, axis=1)  # Assuming the predicted probabilities are in one-hot encoded format\n",
    "\n",
    "# Collect the true class labels for the train data\n",
    "train_true_labels = train_generator.classes\n",
    "\n",
    "# Compute the confusion matrix for the train data\n",
    "train_cm = classification_report(train_true_labels, train_pred_labels)\n",
    "\n",
    "# Generate predictions for the test data\n",
    "test_pred = model.predict(test_generator)\n",
    "test_pred_labels = np.argmax(test_pred, axis=1)  # Assuming the predicted probabilities are in one-hot encoded format\n",
    "\n",
    "# Collect the true class labels for the test data\n",
    "test_true_labels = test_generator.classes\n",
    "\n",
    "# Compute the confusion matrix for the test data\n",
    "test_cm = classification_report(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(\"Confusion Matrix (Train Data):\")\n",
    "print(train_cm)\n",
    "\n",
    "print(\"Confusion Matrix (Test Data):\")\n",
    "print(test_cm)\n",
    "\n",
    "# Get the training loss and accuracy values from the history object\n",
    "train_loss = history.history['loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "\n",
    "# Get the validation loss and accuracy values from the history object\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig()\n",
    "\n",
    "## 5. Xception\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the pre-trained Xception model\n",
    "xception_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in xception_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a custom classification head on top of the pre-trained model\n",
    "global_avg_pooling = GlobalAveragePooling2D()(xception_model.output)\n",
    "dense1 = Dense(256, activation='relu')(global_avg_pooling)\n",
    "output = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=xception_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "epochs = 20  # Adjust the number of epochs as needed\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs, validation_data=test_generator\n",
    ")\n",
    "\n",
    "# Generate predictions for the train data\n",
    "train_pred = model.predict(train_generator)\n",
    "train_pred_labels = np.argmax(train_pred, axis=1)  # Assuming the predicted probabilities are in one-hot encoded format\n",
    "\n",
    "# Collect the true class labels for the train data\n",
    "train_true_labels = train_generator.classes\n",
    "\n",
    "# Compute the confusion matrix for the train data\n",
    "train_cm = classification_report(train_true_labels, train_pred_labels)\n",
    "\n",
    "# Generate predictions for the test data\n",
    "test_pred = model.predict(test_generator)\n",
    "test_pred_labels = np.argmax(test_pred, axis=1)  # Assuming the predicted probabilities are in one-hot encoded format\n",
    "\n",
    "# Collect the true class labels for the test data\n",
    "test_true_labels = test_generator.classes\n",
    "\n",
    "# Compute the confusion matrix for the test data\n",
    "test_cm = classification_report(test_true_labels, test_pred_labels)\n",
    "\n",
    "print(\"Confusion Matrix (Train Data):\")\n",
    "print(train_cm)\n",
    "\n",
    "print(\"Confusion Matrix (Test Data):\")\n",
    "print(test_cm)\n",
    "\n",
    "# Get the training loss and accuracy values from the history object\n",
    "train_loss = history.history['loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "\n",
    "# Get the validation loss and accuracy values from the history object\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
